{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On-premise model\n",
    "\n",
    "- Learning goal: basic examples of loading models from HuggingFace and using them as on-premise models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Image classification model\n",
    "\n",
    "HuggingFace is a *model hub* where developers and companies share their own models for different tasks (image classification, language models, and more). Take a look to get a grasp of the different types of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"image-classification\", model=\"microsoft/resnet-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates an object `pipe` that contains the preprocessing and modeling steps (using the deep learning python library Pytorch) to be able to use the model. The first time, it also downloads the model parameters. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "The model data is downloaded (in its own format) to folder ~/.cache/huggingface/hub/. Be aware this folder may fill up quickly with lots of data if you try many models.\n",
    "\n",
    "As you keep downloading models, you can maintain your HF cache clean by running `huggingface-cli delete-cache`. Install this command with\n",
    "\n",
    "        pip install -U \"huggingface_hub[cli]\"\n",
    "</div>\n",
    "\n",
    "Now let's open an image and classify it. Notice to deal with images we'll use the `PIL` library. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "PATH = \"/Users/joseantonio.rodriguez15/Downloads/images\"\n",
    "full_path = f\"{PATH}/bridge-667997_1280.jpg\"\n",
    "image = Image.open(full_path)\n",
    "result = pipe.predict(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'suspension bridge', 'score': 0.49418672919273376},\n",
       " {'label': 'pier', 'score': 0.4644697606563568},\n",
       " {'label': 'steel arch bridge', 'score': 0.01002844050526619},\n",
       " {'label': 'promontory, headland, head, foreland',\n",
       "  'score': 0.0017029233276844025},\n",
       " {'label': 'worm fence, snake fence, snake-rail fence, Virginia fence',\n",
       "  'score': 0.0016283815493807197}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get the idea. \n",
    "\n",
    "The pipeline object is very handy when you just need to apply a model. The `transformers` library offers a few ways to give you more control of the underlying pytorch object (see notebook `1b_pytorch.ipynb`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_proto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
