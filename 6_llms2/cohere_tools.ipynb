{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper tool use in Cohere\n",
    "\n",
    "Learning goal: Understand the mechanism provided by cohere to officially support \n",
    "tool use in LLMs. \n",
    "\n",
    "## Short description\n",
    "\n",
    "- We will use a LLM to answer questions normally, except that we define a \"tool\" that performs some functionality (in this case, getting the exact calories of a food item).\n",
    "- Cohere offers a mechanism so that this tool is registered -- in which case \n",
    "the LLM can \"pay attention\" to whatever question that seems to need the tool and\n",
    "alerts us. \n",
    "- In such a case, we shoud run the tool incorporate the result in the chat history, \n",
    "and query the LLM again.\n",
    "\n",
    "## Environment preparation\n",
    "\n",
    "First, load your API keys and initialize the API manager objects. We will use `cohere`as LLM and will use the Open Food Facts API to query information about calories of food items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import json\n",
    "import openfoodfacts\n",
    "\n",
    "with open(\"cohere.key\") as f:\n",
    "    COHERE_API_KEY = f.read()\n",
    "cohere_client = cohere.ClientV2(COHERE_API_KEY)\n",
    "api = openfoodfacts.API(user_agent=\"MyAwesomeApp/1.0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the tool\n",
    "\n",
    "Making cohere aware of the tool requires two steps. The first is defining what the tool\n",
    "does as a python function. \n",
    "\n",
    "Here is a function that gets the name of a food item, queries the Open Food Facts database, \n",
    "and returns the number of calories of the item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calories(name):\n",
    "    \"\"\"\n",
    "    Get the calories of a product by its name.\n",
    "    \"\"\"\n",
    "    result = api.product.text_search(name)\n",
    "\n",
    "    # This just takes the first item of the search. \n",
    "    # In a real application, you would need to do more error checking.\n",
    "    first_match = result['products'][0]\n",
    "    id = first_match['_id']\n",
    "    result = api.product.get(id, fields=[\"code\", \"product_name\", \"energy-kcal_100g\"])\n",
    "    return result['energy-kcal_100g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to write a dictionary in a specific format. \n",
    "\n",
    "That object \n",
    "- Defines the name of the function.\n",
    "- Describes what the tool does. \n",
    "- Defines the arguments for the tool. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_calories\",\n",
    "            \"description\": \"Gets the exact calories of a given food item\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"product\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"the name of the food item, e.g. Donettes\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"product\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the tool in the LLM\n",
    "\n",
    "### a) Making the call\n",
    "\n",
    "In order to make the LLM aware of the tool, we just add the argument\n",
    "`tools` to the call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input()\n",
    "\n",
    "messages = [\n",
    "    {'role': 'user', 'content': user_input}\n",
    "]\n",
    "\n",
    "response = cohere_client.chat(\n",
    "    model=\"command-a-03-2025\", messages=messages, tools=tools\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What occurs exactly when we use this? The LLM *internally* evaluates if the question is\n",
    "related to the functionality of the tool. It does so by **comparing the question with \n",
    "the description of the tool**. \n",
    "\n",
    "Note that, if the question is unrelated to calories of food items, the LLM will respond normally. But if the question is related to calories, note the response of the LLM outputs the so-called \"tool plan\".\n",
    "\n",
    "The tool plan includes a text message with an intention of what the LLM plans to do, but also the specific information (name of function and arguments) that it will execute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"id\": \"get_calories_egmjf4txxrgp\",\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"get_calories\",\n",
      "        \"arguments\": \"{\\\"product\\\":\\\"Mikado\\\"}\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"tool_plan\": \"I will look up the number of calories in a bag of Mikado.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.message.json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, let's keep track of all these messages, as we will need them later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.message.tool_calls:\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"tool_plan\": response.message.tool_plan,\n",
    "            \"tool_calls\": response.message.tool_calls,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Executing the tool\n",
    "\n",
    "The LLM software can't execute the tool, this is the responsibility of the \n",
    "programmer. \n",
    "\n",
    "However, the response object has the information structured in a way that already systematizes the tool call. \n",
    "\n",
    "Here is an example for our tool. Note if you had more than one tool, the code for each tool would be repetitive and you can even factor it easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.message.tool_calls:\n",
    "    for tc in response.message.tool_calls:\n",
    "\n",
    "        if tc.function.name == 'get_calories':\n",
    "            dict_string = tc.function.arguments\n",
    "            arg_dict = json.loads(dict_string)\n",
    "            calories = get_calories(arg_dict[\"product\"])\n",
    "\n",
    "            calories_message = f\"\"\"\n",
    "            According to the OpenFoodFacts database, the calories of {arg_dict[\"product\"]}\n",
    "            are {calories}\n",
    "            \"\"\"\n",
    "\n",
    "            messages.append({'role': 'tool', 'tool_call_id': tc.id, 'content': calories_message})\n",
    "        else:\n",
    "            raise ValueError(\"Unknown tool\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we collect the messages and store them in the `messages` list, which now contains everything we've added: \n",
    "\n",
    "- The original message\n",
    "- The response by the LLM with the tool plan\n",
    "- The output of the tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Number of calories in a bag of Mikado'},\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'get_calories_egmjf4txxrgp',\n",
       "  'content': '\\n            According to the OpenFoodFacts database, the calories of Mikado\\n            are 477\\n            '},\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'get_calories_egmjf4txxrgp',\n",
       "  'content': '\\n            According to the OpenFoodFacts database, the calories of Mikado\\n            are 477\\n            '}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Making the final call\n",
    "\n",
    "With that information, we can now make the final call to the LLM. \n",
    "When seeing all these messages, the LLM will compile the final answer from the original question and the tool response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "status_code: 400, body: {'message': \"invalid tool message at messages[1]: tool call id 'get_calories_egmjf4txxrgp' not found in previous tool calls\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/joseantonio.rodriguez15/code/PDAI25/6_llms2/cohere_tools.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/joseantonio.rodriguez15/code/PDAI25/6_llms2/cohere_tools.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response \u001b[39m=\u001b[39m cohere_client\u001b[39m.\u001b[39;49mchat(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joseantonio.rodriguez15/code/PDAI25/6_llms2/cohere_tools.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joseantonio.rodriguez15/code/PDAI25/6_llms2/cohere_tools.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcommand-r-plus\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joseantonio.rodriguez15/code/PDAI25/6_llms2/cohere_tools.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[0;32m~/code/PDAI25/env_proto/lib/python3.9/site-packages/cohere/client.py:103\u001b[0m, in \u001b[0;36mexperimental_kwarg_decorator.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m check_kwarg(deprecated_kwarg, kwargs):\n\u001b[1;32m     99\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    100\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe `\u001b[39m\u001b[39m{\u001b[39;00mdeprecated_kwarg\u001b[39m}\u001b[39;00m\u001b[39m` parameter is an experimental feature and may change in future releases.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo suppress this warning, set `log_warning_experimental_features=False` when initializing the client.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     )\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/code/PDAI25/env_proto/lib/python3.9/site-packages/cohere/client.py:35\u001b[0m, in \u001b[0;36mvalidate_args.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_wrapped\u001b[39m(\u001b[39m*\u001b[39margs: typing\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: typing\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mAny:\n\u001b[1;32m     34\u001b[0m     check_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/code/PDAI25/env_proto/lib/python3.9/site-packages/cohere/v2/client.py:596\u001b[0m, in \u001b[0;36mV2Client.chat\u001b[0;34m(self, model, messages, tools, strict_tools, documents, citation_options, response_format, safety_mode, max_tokens, stop_sequences, temperature, seed, frequency_penalty, presence_penalty, k, p, return_prompt, logprobs, tool_choice, request_options)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[39mreturn\u001b[39;00m typing\u001b[39m.\u001b[39mcast(\n\u001b[1;32m    589\u001b[0m         ChatResponse,\n\u001b[1;32m    590\u001b[0m         construct_type(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    593\u001b[0m         ),\n\u001b[1;32m    594\u001b[0m     )\n\u001b[1;32m    595\u001b[0m \u001b[39mif\u001b[39;00m _response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m400\u001b[39m:\n\u001b[0;32m--> 596\u001b[0m     \u001b[39mraise\u001b[39;00m BadRequestError(\n\u001b[1;32m    597\u001b[0m         typing\u001b[39m.\u001b[39mcast(\n\u001b[1;32m    598\u001b[0m             typing\u001b[39m.\u001b[39mOptional[typing\u001b[39m.\u001b[39mAny],\n\u001b[1;32m    599\u001b[0m             construct_type(\n\u001b[1;32m    600\u001b[0m                 type_\u001b[39m=\u001b[39mtyping\u001b[39m.\u001b[39mOptional[typing\u001b[39m.\u001b[39mAny],  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    601\u001b[0m                 object_\u001b[39m=\u001b[39m_response\u001b[39m.\u001b[39mjson(),\n\u001b[1;32m    602\u001b[0m             ),\n\u001b[1;32m    603\u001b[0m         )\n\u001b[1;32m    604\u001b[0m     )\n\u001b[1;32m    605\u001b[0m \u001b[39mif\u001b[39;00m _response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[1;32m    606\u001b[0m     \u001b[39mraise\u001b[39;00m UnauthorizedError(\n\u001b[1;32m    607\u001b[0m         typing\u001b[39m.\u001b[39mcast(\n\u001b[1;32m    608\u001b[0m             typing\u001b[39m.\u001b[39mOptional[typing\u001b[39m.\u001b[39mAny],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m         )\n\u001b[1;32m    614\u001b[0m     )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: status_code: 400, body: {'message': \"invalid tool message at messages[1]: tool call id 'get_calories_egmjf4txxrgp' not found in previous tool calls\"}"
     ]
    }
   ],
   "source": [
    "response = cohere_client.chat(\n",
    "    messages=messages,\n",
    "    model=\"command-r-plus\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing of the tool is that the output object contains the \"grounding\" information: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"fea0d8dd-ea6c-4577-bdc1-3d9ca5f56f8c\",\n",
      "   \"finish_reason\": \"TOOL_CALL\",\n",
      "   \"message\": {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "         {\n",
      "            \"id\": \"get_calories_egmjf4txxrgp\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "               \"name\": \"get_calories\",\n",
      "               \"arguments\": \"{\\\"product\\\":\\\"Mikado\\\"}\"\n",
      "            }\n",
      "         }\n",
      "      ],\n",
      "      \"tool_plan\": \"I will look up the number of calories in a bag of Mikado.\"\n",
      "   },\n",
      "   \"usage\": {\n",
      "      \"billed_units\": {\n",
      "         \"input_tokens\": 37.0,\n",
      "         \"output_tokens\": 25.0\n",
      "      },\n",
      "      \"tokens\": {\n",
      "         \"input_tokens\": 1459.0,\n",
      "         \"output_tokens\": 54.0\n",
      "      }\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.json(indent=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_proto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
